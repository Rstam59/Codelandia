{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH6PmdcCMOlpMA/YLDOIce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rstam59/TaskDataRepoForStudents/blob/main/09_SkimLit_NLP_milestone_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2eKw9GL3k3f",
        "outputId": "9f0a1c43-fe98-4fbe-ce17-c3bb8c5622f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 18.28 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "B_VwYYpX9h-x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_names = [data_dir + file_name for file_name in os.listdir(data_dir)]\n",
        "file_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgIQctTfEam0",
        "outputId": "f0ac06cb-c4c3-4ef0-e09d-640b3f6dbf9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "rdywntpDEvOL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + 'train.txt')\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eV3vN8cU0hO",
        "outputId": "353a1f2f-981b-419f-dc4c-5599011a1f59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QKbJGeeZnIV",
        "outputId": "ceae3423-f350-4c9b-df08-f11ef3a463b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples\n"
      ],
      "metadata": {
        "id": "MUmkRcn5l7uM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = preprocess_text_with_line_numbers(data_dir + 'train.txt')\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + 'dev.txt')\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + 'test.txt')\n",
        "print(len(train_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRqeeqqQl_ND",
        "outputId": "a249e475-8d1e-47f3-b44e-fd0752eff994"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikkRBRssjsqK",
        "outputId": "78a2b462-d0fc-49a0-a884-487d61a76fb3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)"
      ],
      "metadata": {
        "id": "MmR5SZrHIXMb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "RNxHBT14G8e7",
        "outputId": "661dbede-9795-4af3-b87a-25501fd0a7b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09d5e9ab-448a-4480-9a27-3892c42bc34a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d5e9ab-448a-4480-9a27-3892c42bc34a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09d5e9ab-448a-4480-9a27-3892c42bc34a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09d5e9ab-448a-4480-9a27-3892c42bc34a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bfe2405-b72f-4bcd-8324-302e8b5c3b5b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bfe2405-b72f-4bcd-8324-302e8b5c3b5b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bfe2405-b72f-4bcd-8324-302e8b5c3b5b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "j15z3zF3G-4U",
        "outputId": "566d4e0b-a78d-43aa-eab6-ef43fb22b644"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>METHODS</th>\n",
              "      <td>59353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULTS</th>\n",
              "      <td>57953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCLUSIONS</th>\n",
              "      <td>27168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BACKGROUND</th>\n",
              "      <td>21727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <td>13839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "SRvu9NbrIaqX",
        "outputId": "8a48e34b-a35e-48e9-822f-253b93542a34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGeCAYAAACJuDVEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA13klEQVR4nO3df1SUdd7/8Rcgg/hjxlABWVEpTSN/rag42497XVlHpU6m7dGyJKO6NXRVMn/sumjdnWztVNrtD7ZtV9yzuSp7p1uyYi4q7iZpYuSPb5KZhS4MWgmjpIBwff/o5rqdML0gbAZ6Ps65zjrX581n3vM5s2deXVzzIcAwDEMAAAC4qkBfNwAAANAcEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFrTydQMtRW1trYqLi9W+fXsFBAT4uh0AAGCBYRg6d+6coqKiFBh4jWtJhg91797dkFTveOKJJwzDMIwLFy4YTzzxhBEWFma0bdvWGDdunOF2u73m+Oyzz4wxY8YYoaGhRufOnY05c+YY1dXVXjU7d+40fvzjHxs2m8246aabjDVr1tTrZcWKFUb37t2NkJAQY+jQocbevXsb9FpOnjx5xdfCwcHBwcHB4f/HyZMnr/lZ79MrTe+9955qamrMx4cPH9bPf/5z/eIXv5AkzZ49W1lZWcrMzJTD4dD06dM1btw4vfPOO5KkmpoaJSYmKjIyUnv27FFJSYkmT56s4OBgPffcc5KkEydOKDExUVOnTtXrr7+unJwcPfroo+rSpYtcLpckacOGDUpNTVV6erri4+O1bNkyuVwuFRYWKjw83NJrad++vSTp5MmTstvtTbZGAADg+vF4PIqOjjY/x6+qQZdTrrOZM2caN910k1FbW2uUlZUZwcHBRmZmpjn+4YcfGpKMvLw8wzAM4+9//7sRGBjodfVp9erVht1uNyorKw3DMIy5c+cat956q9fzTJgwwXC5XObjoUOHGikpKebjmpoaIyoqyliyZInl3svLyw1JRnl5ecNeNAAA8JmGfH77zY3gVVVV+vOf/6xHHnlEAQEBys/PV3V1tRISEsyaPn36qFu3bsrLy5Mk5eXlqV+/foqIiDBrXC6XPB6Pjhw5YtZcPkddTd0cVVVVys/P96oJDAxUQkKCWXMllZWV8ng8XgcAAGi5/CY0bd68WWVlZXr44YclSW63WzabTR06dPCqi4iIkNvtNmsuD0x143VjV6vxeDy6cOGCPv/8c9XU1Fyxpm6OK1myZIkcDod5REdHN/g1AwCA5sNvQtMf/vAHjR49WlFRUb5uxZIFCxaovLzcPE6ePOnrlgAAwHXkF1sOfPbZZ/rHP/6hN954wzwXGRmpqqoqlZWVeV1tKi0tVWRkpFmzb98+r7lKS0vNsbr/rTt3eY3dbldoaKiCgoIUFBR0xZq6Oa4kJCREISEhDX+xAACgWfKLK01r1qxReHi4EhMTzXNxcXEKDg5WTk6Oea6wsFBFRUVyOp2SJKfTqUOHDun06dNmzfbt22W32xUbG2vWXD5HXU3dHDabTXFxcV41tbW1ysnJMWsAAAB8fqWptrZWa9asUVJSklq1+r92HA6HkpOTlZqaqrCwMNntds2YMUNOp1PDhg2TJI0cOVKxsbF66KGHtHTpUrndbi1cuFApKSnmVaCpU6dqxYoVmjt3rh555BHt2LFDGzduVFZWlvlcqampSkpK0uDBgzV06FAtW7ZMFRUVmjJlyve7GAAAwH99D9/mu6pt27YZkozCwsJ6Y3WbW95www1GmzZtjHvvvdcoKSnxqvn000+N0aNHG6GhoUanTp2MJ5988oqbWw4cONCw2WzGjTfeeMXNLf/7v//b6Natm2Gz2YyhQ4ca7777boNeB1sOAADQ/DTk8zvAMAzDx7mtRfB4PHI4HCovL2dzSwAAmomGfH77xT1NAAAA/o7QBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABb4fHNLwJ/0mJ917SI/8+nzidcuAgB8Z1xpAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGCBz0PTv//9bz344IPq2LGjQkND1a9fP+3fv98cNwxDaWlp6tKli0JDQ5WQkKBjx455zfHll19q0qRJstvt6tChg5KTk3X+/HmvmoMHD+qOO+5Q69atFR0draVLl9brJTMzU3369FHr1q3Vr18//f3vf78+LxoAADQ7Pg1NZ8+e1W233abg4GBt3bpV/+///T+9+OKLuuGGG8yapUuX6pVXXlF6err27t2rtm3byuVy6eLFi2bNpEmTdOTIEW3fvl1btmzR7t279fjjj5vjHo9HI0eOVPfu3ZWfn68XXnhBixcv1quvvmrW7NmzR/fff7+Sk5P1/vvva+zYsRo7dqwOHz78/SwGAADwawGGYRi+evL58+frnXfe0T//+c8rjhuGoaioKD355JOaM2eOJKm8vFwRERHKyMjQxIkT9eGHHyo2NlbvvfeeBg8eLEnKzs7WmDFjdOrUKUVFRWn16tX69a9/LbfbLZvNZj735s2bdfToUUnShAkTVFFRoS1btpjPP2zYMA0cOFDp6enXfC0ej0cOh0Pl5eWy2+3faV3gOz3mZ/m6hQb79PlEX7cAAM1WQz6/fXql6c0339TgwYP1i1/8QuHh4frxj3+s3//+9+b4iRMn5Ha7lZCQYJ5zOByKj49XXl6eJCkvL08dOnQwA5MkJSQkKDAwUHv37jVr7rzzTjMwSZLL5VJhYaHOnj1r1lz+PHU1dc/zTZWVlfJ4PF4HAABouXwamj755BOtXr1avXr10rZt2zRt2jT98pe/1Nq1ayVJbrdbkhQREeH1cxEREeaY2+1WeHi413irVq0UFhbmVXOlOS5/jm+rqRv/piVLlsjhcJhHdHR0g18/AABoPnwammprazVo0CA999xz+vGPf6zHH39cjz32mKVfh/naggULVF5ebh4nT570dUsAAOA68mlo6tKli2JjY73O3XLLLSoqKpIkRUZGSpJKS0u9akpLS82xyMhInT592mv80qVL+vLLL71qrjTH5c/xbTV1498UEhIiu93udQAAgJbLp6HptttuU2Fhode5jz76SN27d5ckxcTEKDIyUjk5Oea4x+PR3r175XQ6JUlOp1NlZWXKz883a3bs2KHa2lrFx8ebNbt371Z1dbVZs337dvXu3dv8pp7T6fR6nrqauucBAAA/bD4NTbNnz9a7776r5557Th9//LHWrVunV199VSkpKZKkgIAAzZo1S88++6zefPNNHTp0SJMnT1ZUVJTGjh0r6esrU6NGjdJjjz2mffv26Z133tH06dM1ceJERUVFSZIeeOAB2Ww2JScn68iRI9qwYYOWL1+u1NRUs5eZM2cqOztbL774oo4eParFixdr//79mj59+ve+LgAAwP+08uWTDxkyRJs2bdKCBQv0zDPPKCYmRsuWLdOkSZPMmrlz56qiokKPP/64ysrKdPvttys7O1utW7c2a15//XVNnz5dI0aMUGBgoMaPH69XXnnFHHc4HHr77beVkpKiuLg4derUSWlpaV57Of3kJz/RunXrtHDhQv3qV79Sr169tHnzZvXt2/f7WQwAAODXfLpPU0vCPk0tA/s0AcAPS7PZpwkAAKC5IDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACzwaWhavHixAgICvI4+ffqY4xcvXlRKSoo6duyodu3aafz48SotLfWao6ioSImJiWrTpo3Cw8P11FNP6dKlS141u3bt0qBBgxQSEqKePXsqIyOjXi8rV65Ujx491Lp1a8XHx2vfvn3X5TUDAIDmyedXmm699VaVlJSYx7/+9S9zbPbs2XrrrbeUmZmp3NxcFRcXa9y4ceZ4TU2NEhMTVVVVpT179mjt2rXKyMhQWlqaWXPixAklJiZq+PDhKigo0KxZs/Too49q27ZtZs2GDRuUmpqqRYsW6cCBAxowYIBcLpdOnz79/SwCAADwewGGYRi+evLFixdr8+bNKigoqDdWXl6uzp07a926dbrvvvskSUePHtUtt9yivLw8DRs2TFu3btVdd92l4uJiRURESJLS09M1b948nTlzRjabTfPmzVNWVpYOHz5szj1x4kSVlZUpOztbkhQfH68hQ4ZoxYoVkqTa2lpFR0drxowZmj9/vqXX4vF45HA4VF5eLrvd/l2WBT7UY36Wr1tosE+fT/R1CwDQbDXk89vnV5qOHTumqKgo3XjjjZo0aZKKiookSfn5+aqurlZCQoJZ26dPH3Xr1k15eXmSpLy8PPXr188MTJLkcrnk8Xh05MgRs+byOepq6uaoqqpSfn6+V01gYKASEhLMGgAAgFa+fPL4+HhlZGSod+/eKikp0dNPP6077rhDhw8fltvtls1mU4cOHbx+JiIiQm63W5Lkdru9AlPdeN3Y1Wo8Ho8uXLigs2fPqqam5oo1R48e/dbeKysrVVlZaT72eDwNe/EAAKBZ8WloGj16tPnv/v37Kz4+Xt27d9fGjRsVGhrqw86ubcmSJXr66ad93QYAAPie+PzXc5fr0KGDbr75Zn388ceKjIxUVVWVysrKvGpKS0sVGRkpSYqMjKz3bbq6x9eqsdvtCg0NVadOnRQUFHTFmro5rmTBggUqLy83j5MnTzbqNQMAgObBr0LT+fPndfz4cXXp0kVxcXEKDg5WTk6OOV5YWKiioiI5nU5JktPp1KFDh7y+5bZ9+3bZ7XbFxsaaNZfPUVdTN4fNZlNcXJxXTW1trXJycsyaKwkJCZHdbvc6AABAy+XT0DRnzhzl5ubq008/1Z49e3TvvfcqKChI999/vxwOh5KTk5WamqqdO3cqPz9fU6ZMkdPp1LBhwyRJI0eOVGxsrB566CF98MEH2rZtmxYuXKiUlBSFhIRIkqZOnapPPvlEc+fO1dGjR7Vq1Spt3LhRs2fPNvtITU3V73//e61du1Yffvihpk2bpoqKCk2ZMsUn6wIAAPyPT+9pOnXqlO6//3598cUX6ty5s26//Xa9++676ty5syTp5ZdfVmBgoMaPH6/Kykq5XC6tWrXK/PmgoCBt2bJF06ZNk9PpVNu2bZWUlKRnnnnGrImJiVFWVpZmz56t5cuXq2vXrnrttdfkcrnMmgkTJujMmTNKS0uT2+3WwIEDlZ2dXe/mcAAA8MPl032aWhL2aWoZ2KcJAH5YmtU+TQAAAM0BoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFjQqNH3yySdN3QcAAIBfa1Ro6tmzp4YPH64///nPunjxYlP3BAAA4HcaFZoOHDig/v37KzU1VZGRkfrP//xP7du3r6l7AwAA8BuNCk0DBw7U8uXLVVxcrD/+8Y8qKSnR7bffrr59++qll17SmTNnmrpPAAAAn/pON4K3atVK48aNU2Zmpn7729/q448/1pw5cxQdHa3JkyerpKTE8lzPP/+8AgICNGvWLPPcxYsXlZKSoo4dO6pdu3YaP368SktLvX6uqKhIiYmJatOmjcLDw/XUU0/p0qVLXjW7du3SoEGDFBISop49eyojI6Pe869cuVI9evRQ69atFR8fz5UzAADg5TuFpv379+uJJ55Qly5d9NJLL2nOnDk6fvy4tm/fruLiYt1zzz2W5nnvvff0u9/9Tv379/c6P3v2bL311lvKzMxUbm6uiouLNW7cOHO8pqZGiYmJqqqq0p49e7R27VplZGQoLS3NrDlx4oQSExM1fPhwFRQUaNasWXr00Ue1bds2s2bDhg1KTU3VokWLdODAAQ0YMEAul0unT5/+LssDAABakADDMIyG/tBLL72kNWvWqLCwUGPGjNGjjz6qMWPGKDDw/zLYqVOn1KNHj3pXfb7p/PnzGjRokFatWqVnn31WAwcO1LJly1ReXq7OnTtr3bp1uu+++yRJR48e1S233KK8vDwNGzZMW7du1V133aXi4mJFRERIktLT0zVv3jydOXNGNptN8+bNU1ZWlg4fPmw+58SJE1VWVqbs7GxJUnx8vIYMGaIVK1ZIkmpraxUdHa0ZM2Zo/vz5ltbE4/HI4XCovLxcdrvd+mLCr/SYn+XrFn4QPn0+0dctAICkhn1+N+pK0+rVq/XAAw/os88+0+bNm3XXXXd5BSZJCg8P1x/+8IdrzpWSkqLExEQlJCR4nc/Pz1d1dbXX+T59+qhbt27Ky8uTJOXl5alfv35mYJIkl8slj8ejI0eOmDXfnNvlcplzVFVVKT8/36smMDBQCQkJZg0AAECrxvzQsWPHrlljs9mUlJR01Zr169frwIEDeu+99+qNud1u2Ww2dejQwet8RESE3G63WXN5YKobrxu7Wo3H49GFCxd09uxZ1dTUXLHm6NGj39p7ZWWlKisrzccej+eqrxUAADRvjbrStGbNGmVmZtY7n5mZqbVr11qa4+TJk5o5c6Zef/11tW7dujFt+NSSJUvkcDjMIzo62tctAQCA66hRoWnJkiXq1KlTvfPh4eF67rnnLM2Rn5+v06dPa9CgQWrVqpVatWql3NxcvfLKK2rVqpUiIiJUVVWlsrIyr58rLS1VZGSkJCkyMrLet+nqHl+rxm63KzQ0VJ06dVJQUNAVa+rmuJIFCxaovLzcPE6ePGnpdQMAgOapUaGpqKhIMTEx9c53795dRUVFluYYMWKEDh06pIKCAvMYPHiwJk2aZP47ODhYOTk55s8UFhaqqKhITqdTkuR0OnXo0CGvb7lt375ddrtdsbGxZs3lc9TV1M1hs9kUFxfnVVNbW6ucnByz5kpCQkJkt9u9DgAA0HI16p6m8PBwHTx4UD169PA6/8EHH6hjx46W5mjfvr369u3rda5t27bq2LGjeT45OVmpqakKCwuT3W7XjBkz5HQ6NWzYMEnSyJEjFRsbq4ceekhLly6V2+3WwoULlZKSopCQEEnS1KlTtWLFCs2dO1ePPPKIduzYoY0bNyor6/++JZWamqqkpCQNHjxYQ4cO1bJly1RRUaEpU6Y0ZnkAAEAL1KjQdP/99+uXv/yl2rdvrzvvvFOSlJubq5kzZ2rixIlN1tzLL7+swMBAjR8/XpWVlXK5XFq1apU5HhQUpC1btmjatGlyOp1q27atkpKS9Mwzz5g1MTExysrK0uzZs7V8+XJ17dpVr732mlwul1kzYcIEnTlzRmlpaXK73Ro4cKCys7Pr3RwOAAB+uBq1T1NVVZUeeughZWZmqlWrr3NXbW2tJk+erPT0dNlstiZv1N+xT1PLwD5N3w/2aQLgLxry+d2oK002m00bNmzQf/3Xf+mDDz5QaGio+vXrp+7duzeqYQAAAH/XqNBU5+abb9bNN9/cVL0AAAD4rUaFppqaGmVkZCgnJ0enT59WbW2t1/iOHTuapDkAAAB/0ajQNHPmTGVkZCgxMVF9+/ZVQEBAU/cFAADgVxoVmtavX6+NGzdqzJgxTd0PAACAX2rU5pY2m009e/Zs6l4AAAD8VqNC05NPPqnly5erEbsVAAAANEuN+vXcv/71L+3cuVNbt27VrbfequDgYK/xN954o0maAwAA8BeNCk0dOnTQvffe29S9AAAA+K1GhaY1a9Y0dR8AAAB+rVH3NEnSpUuX9I9//EO/+93vdO7cOUlScXGxzp8/32TNAQAA+ItGXWn67LPPNGrUKBUVFamyslI///nP1b59e/32t79VZWWl0tPTm7pPAAAAn2rUlaaZM2dq8ODBOnv2rEJDQ83z9957r3JycpqsOQAAAH/RqCtN//znP7Vnzx7ZbDav8z169NC///3vJmkMAADAnzTqSlNtba1qamrqnT916pTat2//nZsCAADwN40KTSNHjtSyZcvMxwEBATp//rwWLVrEn1YBAAAtUqN+Pffiiy/K5XIpNjZWFy9e1AMPPKBjx46pU6dO+stf/tLUPQIAAPhco0JT165d9cEHH2j9+vU6ePCgzp8/r+TkZE2aNMnrxnAAAICWolGhSZJatWqlBx98sCl7AQAA8FuNCk1/+tOfrjo+efLkRjUDAADgrxoVmmbOnOn1uLq6Wl999ZVsNpvatGlDaAIAAC1Oo749d/bsWa/j/PnzKiws1O23386N4AAAoEVq9N+e+6ZevXrp+eefr3cVCgAAoCVostAkfX1zeHFxcVNOCQAA4BcadU/Tm2++6fXYMAyVlJRoxYoVuu2225qkMQAAAH/SqNA0duxYr8cBAQHq3Lmzfvazn+nFF19sir4AAAD8SqNCU21tbVP3AQAA4Nea9J4mAACAlqpRV5pSU1Mt17700kuNeQoAAAC/0qjQ9P777+v9999XdXW1evfuLUn66KOPFBQUpEGDBpl1AQEBTdMlAACAjzUqNN19991q37691q5dqxtuuEHS1xteTpkyRXfccYeefPLJJm0SAADA1wIMwzAa+kM/+tGP9Pbbb+vWW2/1On/48GGNHDnyB7lXk8fjkcPhUHl5uex2u6/bQSP1mJ/l6xbgpz59PtHXLQC4Dhry+d2oG8E9Ho/OnDlT7/yZM2d07ty5xkwJAADg1xoVmu69915NmTJFb7zxhk6dOqVTp07pf/7nf5ScnKxx48Y1dY8AAAA+16h7mtLT0zVnzhw98MADqq6u/nqiVq2UnJysF154oUkbBAAA8AeNCk1t2rTRqlWr9MILL+j48eOSpJtuuklt27Zt0uYAAAD8xXfa3LKkpEQlJSXq1auX2rZtq0bcUw4AANAsNCo0ffHFFxoxYoRuvvlmjRkzRiUlJZKk5ORkthsAAAAtUqNC0+zZsxUcHKyioiK1adPGPD9hwgRlZ2c3WXMAAAD+olH3NL399tvatm2bunbt6nW+V69e+uyzz5qkMQAAAH/SqCtNFRUVXleY6nz55ZcKCQn5zk0BAAD4m0aFpjvuuEN/+tOfzMcBAQGqra3V0qVLNXz48CZrDgAAwF80KjQtXbpUr776qkaPHq2qqirNnTtXffv21e7du/Xb3/7W8jyrV69W//79ZbfbZbfb5XQ6tXXrVnP84sWLSklJUceOHdWuXTuNHz9epaWlXnMUFRUpMTFRbdq0UXh4uJ566ildunTJq2bXrl0aNGiQQkJC1LNnT2VkZNTrZeXKlerRo4dat26t+Ph47du3r2GLAgAAWrRGhaa+ffvqo48+0u2336577rlHFRUVGjdunN5//33ddNNNlufp2rWrnn/+eeXn52v//v362c9+pnvuuUdHjhyR9PUN52+99ZYyMzOVm5ur4uJirx3Ha2pqlJiYqKqqKu3Zs0dr165VRkaG0tLSzJoTJ04oMTFRw4cPV0FBgWbNmqVHH31U27ZtM2s2bNig1NRULVq0SAcOHNCAAQPkcrl0+vTpxiwPAABogRr8B3urq6s1atQopaenq1evXk3eUFhYmF544QXdd9996ty5s9atW6f77rtPknT06FHdcsstysvL07Bhw7R161bdddddKi4uVkREhKSvdyufN2+ezpw5I5vNpnnz5ikrK0uHDx82n2PixIkqKyszv+kXHx+vIUOGaMWKFZKk2tpaRUdHa8aMGZo/f76lvvmDvS0Df7AX34Y/2Au0TNf1D/YGBwfr4MGDjW7u29TU1Gj9+vWqqKiQ0+lUfn6+qqurlZCQYNb06dNH3bp1U15eniQpLy9P/fr1MwOTJLlcLnk8HvNqVV5entccdTV1c1RVVSk/P9+rJjAwUAkJCWbNlVRWVsrj8XgdAACg5WrUr+cefPBB/eEPf2iSBg4dOqR27dopJCREU6dO1aZNmxQbGyu32y2bzaYOHTp41UdERMjtdkuS3G63V2CqG68bu1qNx+PRhQsX9Pnnn6umpuaKNXVzXMmSJUvkcDjMIzo6ulGvHwAANA+N2qfp0qVL+uMf/6h//OMfiouLq/c351566SXLc/Xu3VsFBQUqLy/XX//6VyUlJSk3N7cxbX2vFixYoNTUVPOxx+MhOAEA0II1KDR98skn6tGjhw4fPqxBgwZJkj766COvmoCAgAY1YLPZ1LNnT0lSXFyc3nvvPS1fvlwTJkxQVVWVysrKvK42lZaWKjIyUpIUGRlZ71tudd+uu7zmm9+4Ky0tld1uV2hoqIKCghQUFHTFmro5riQkJIQ9qQAA+AFp0K/nevXqpc8//1w7d+7Uzp07FR4ervXr15uPd+7cqR07dnynhmpra1VZWam4uDgFBwcrJyfHHCssLFRRUZGcTqckyel06tChQ17fctu+fbvsdrtiY2PNmsvnqKupm8NmsykuLs6rpra2Vjk5OWYNAABAg640ffOLdlu3blVFRUWjn3zBggUaPXq0unXrpnPnzmndunXatWuXtm3bJofDoeTkZKWmpiosLEx2u10zZsyQ0+nUsGHDJEkjR45UbGysHnroIS1dulRut1sLFy5USkqKeRVo6tSpWrFihebOnatHHnlEO3bs0MaNG5WV9X/fkkpNTVVSUpIGDx6soUOHatmyZaqoqNCUKVMa/doAAEDL0qh7muo0cLeCek6fPq3JkyerpKREDodD/fv317Zt2/Tzn/9ckvTyyy8rMDBQ48ePV2VlpVwul1atWmX+fFBQkLZs2aJp06bJ6XSqbdu2SkpK0jPPPGPWxMTEKCsrS7Nnz9by5cvVtWtXvfbaa3K5XGbNhAkTdObMGaWlpcntdmvgwIHKzs6ud3M4AAD44WrQPk1BQUFyu93q3LmzJKl9+/Y6ePCgYmJirluDzQX7NLUM7NOEb8M+TUDL1JDP7wb/eu7hhx82f/V18eJFTZ06td635954440GtgwAAODfGhSakpKSvB4/+OCDTdoMAACAv2pQaFqzZs316gMAAMCvNWpHcAAAgB8aQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFrXzdAFquHvOzfN0CAABNhitNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFjg09C0ZMkSDRkyRO3bt1d4eLjGjh2rwsJCr5qLFy8qJSVFHTt2VLt27TR+/HiVlpZ61RQVFSkxMVFt2rRReHi4nnrqKV26dMmrZteuXRo0aJBCQkLUs2dPZWRk1Otn5cqV6tGjh1q3bq34+Hjt27evyV8zAABonnwamnJzc5WSkqJ3331X27dvV3V1tUaOHKmKigqzZvbs2XrrrbeUmZmp3NxcFRcXa9y4ceZ4TU2NEhMTVVVVpT179mjt2rXKyMhQWlqaWXPixAklJiZq+PDhKigo0KxZs/Too49q27ZtZs2GDRuUmpqqRYsW6cCBAxowYIBcLpdOnz79/SwGAADwawGGYRi+bqLOmTNnFB4ertzcXN15550qLy9X586dtW7dOt13332SpKNHj+qWW25RXl6ehg0bpq1bt+quu+5ScXGxIiIiJEnp6emaN2+ezpw5I5vNpnnz5ikrK0uHDx82n2vixIkqKytTdna2JCk+Pl5DhgzRihUrJEm1tbWKjo7WjBkzNH/+/Gv27vF45HA4VF5eLrvd3tRL0yz1mJ/l6xaAJvPp84m+bgHAddCQz2+/uqepvLxckhQWFiZJys/PV3V1tRISEsyaPn36qFu3bsrLy5Mk5eXlqV+/fmZgkiSXyyWPx6MjR46YNZfPUVdTN0dVVZXy8/O9agIDA5WQkGDWfFNlZaU8Ho/XAQAAWi6/CU21tbWaNWuWbrvtNvXt21eS5Ha7ZbPZ1KFDB6/aiIgIud1us+bywFQ3Xjd2tRqPx6MLFy7o888/V01NzRVr6ub4piVLlsjhcJhHdHR04144AABoFvwmNKWkpOjw4cNav369r1uxZMGCBSovLzePkydP+rolAABwHbXydQOSNH36dG3ZskW7d+9W165dzfORkZGqqqpSWVmZ19Wm0tJSRUZGmjXf/JZb3bfrLq/55jfuSktLZbfbFRoaqqCgIAUFBV2xpm6ObwoJCVFISEjjXjAAAGh2fHqlyTAMTZ8+XZs2bdKOHTsUExPjNR4XF6fg4GDl5OSY5woLC1VUVCSn0ylJcjqdOnTokNe33LZv3y673a7Y2Fiz5vI56mrq5rDZbIqLi/Oqqa2tVU5OjlkDAAB+2Hx6pSklJUXr1q3T3/72N7Vv3968f8jhcCg0NFQOh0PJyclKTU1VWFiY7Ha7ZsyYIafTqWHDhkmSRo4cqdjYWD300ENaunSp3G63Fi5cqJSUFPNK0NSpU7VixQrNnTtXjzzyiHbs2KGNGzcqK+v/vt2VmpqqpKQkDR48WEOHDtWyZctUUVGhKVOmfP8LAwAA/I5PQ9Pq1aslST/96U+9zq9Zs0YPP/ywJOnll19WYGCgxo8fr8rKSrlcLq1atcqsDQoK0pYtWzRt2jQ5nU61bdtWSUlJeuaZZ8yamJgYZWVlafbs2Vq+fLm6du2q1157TS6Xy6yZMGGCzpw5o7S0NLndbg0cOFDZ2dn1bg4HAAA/TH61T1Nzxj5N9bFPE1oS9mkCWqZmu08TAACAvyI0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWtPJ1AwDQHPSYn+XrFhrs0+cTfd0C0KL49ErT7t27dffddysqKkoBAQHavHmz17hhGEpLS1OXLl0UGhqqhIQEHTt2zKvmyy+/1KRJk2S329WhQwclJyfr/PnzXjUHDx7UHXfcodatWys6OlpLly6t10tmZqb69Omj1q1bq1+/fvr73//e5K8XAAA0Xz4NTRUVFRowYIBWrlx5xfGlS5fqlVdeUXp6uvbu3au2bdvK5XLp4sWLZs2kSZN05MgRbd++XVu2bNHu3bv1+OOPm+Mej0cjR45U9+7dlZ+frxdeeEGLFy/Wq6++atbs2bNH999/v5KTk/X+++9r7NixGjt2rA4fPnz9XjwAAGhWAgzDMHzdhCQFBARo06ZNGjt2rKSvrzJFRUXpySef1Jw5cyRJ5eXlioiIUEZGhiZOnKgPP/xQsbGxeu+99zR48GBJUnZ2tsaMGaNTp04pKipKq1ev1q9//Wu53W7ZbDZJ0vz587V582YdPXpUkjRhwgRVVFRoy5YtZj/Dhg3TwIEDlZ6ebql/j8cjh8Oh8vJy2e32plqWZq05/joDaEn49RxwbQ35/PbbG8FPnDght9uthIQE85zD4VB8fLzy8vIkSXl5eerQoYMZmCQpISFBgYGB2rt3r1lz5513moFJklwulwoLC3X27Fmz5vLnqaupe54rqayslMfj8ToAAEDL5behye12S5IiIiK8zkdERJhjbrdb4eHhXuOtWrVSWFiYV82V5rj8Ob6tpm78SpYsWSKHw2Ee0dHRDX2JAACgGfHb0OTvFixYoPLycvM4efKkr1sCAADXkd+GpsjISElSaWmp1/nS0lJzLDIyUqdPn/Yav3Tpkr788kuvmivNcflzfFtN3fiVhISEyG63ex0AAKDl8tvQFBMTo8jISOXk5JjnPB6P9u7dK6fTKUlyOp0qKytTfn6+WbNjxw7V1tYqPj7erNm9e7eqq6vNmu3bt6t379664YYbzJrLn6eupu55AAAAfBqazp8/r4KCAhUUFEj6+ubvgoICFRUVKSAgQLNmzdKzzz6rN998U4cOHdLkyZMVFRVlfsPulltu0ahRo/TYY49p3759eueddzR9+nRNnDhRUVFRkqQHHnhANptNycnJOnLkiDZs2KDly5crNTXV7GPmzJnKzs7Wiy++qKNHj2rx4sXav3+/pk+f/n0vCQAA8FM+3RF8//79Gj58uPm4LsgkJSUpIyNDc+fOVUVFhR5//HGVlZXp9ttvV3Z2tlq3bm3+zOuvv67p06drxIgRCgwM1Pjx4/XKK6+Y4w6HQ2+//bZSUlIUFxenTp06KS0tzWsvp5/85Cdat26dFi5cqF/96lfq1auXNm/erL59+34PqwAAAJoDv9mnqbljn6b62KcJ8C32aQKurUXs0wQAAOBPCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALGjl6wYAANdHj/lZvm6hwT59PtHXLQDfiitNAAAAFhCaAAAALODXc81Ec7zMDgBAS0JoAgD4jeb4H4jch/XDwa/nAAAALCA0fcPKlSvVo0cPtW7dWvHx8dq3b5+vWwIAAH6A0HSZDRs2KDU1VYsWLdKBAwc0YMAAuVwunT592tetAQAAHyM0Xeall17SY489pilTpig2Nlbp6elq06aN/vjHP/q6NQAA4GPcCP6/qqqqlJ+frwULFpjnAgMDlZCQoLy8vHr1lZWVqqysNB+Xl5dLkjwez3Xpr7byq+syLwDgu+k2O9PXLTTK4addvm7BL9R9bhuGcc1aQtP/+vzzz1VTU6OIiAiv8xERETp69Gi9+iVLlujpp5+udz46Ovq69QgAQFNxLPN1B/7l3LlzcjgcV60hNDXSggULlJqaaj6ura3Vl19+qY4dOyogIMCHnV0fHo9H0dHROnnypOx2u6/bafZYz6bDWjYt1rPpsJZN63qtp2EYOnfunKKioq5ZS2j6X506dVJQUJBKS0u9zpeWlioyMrJefUhIiEJCQrzOdejQ4Xq26Bfsdjv/529CrGfTYS2bFuvZdFjLpnU91vNaV5jqcCP4/7LZbIqLi1NOTo55rra2Vjk5OXI6nT7sDAAA+AOuNF0mNTVVSUlJGjx4sIYOHaply5apoqJCU6ZM8XVrAADAxwhNl5kwYYLOnDmjtLQ0ud1uDRw4UNnZ2fVuDv8hCgkJ0aJFi+r9ShKNw3o2HdayabGeTYe1bFr+sJ4BhpXv2AEAAPzAcU8TAACABYQmAAAACwhNAAAAFhCaAAAALCA04aoWL16sgIAAr6NPnz6+bqtZ2L17t+6++25FRUUpICBAmzdv9ho3DENpaWnq0qWLQkNDlZCQoGPHjvmm2WbgWuv58MMP13uvjho1yjfN+rklS5ZoyJAhat++vcLDwzV27FgVFhZ61Vy8eFEpKSnq2LGj2rVrp/Hjx9fb/BfW1vKnP/1pvffm1KlTfdSxf1u9erX69+9vbmDpdDq1detWc9zX70tCE67p1ltvVUlJiXn861//8nVLzUJFRYUGDBiglStXXnF86dKleuWVV5Senq69e/eqbdu2crlcunjx4vfcafNwrfWUpFGjRnm9V//yl798jx02H7m5uUpJSdG7776r7du3q7q6WiNHjlRFRYVZM3v2bL311lvKzMxUbm6uiouLNW7cOB927Z+srKUkPfbYY17vzaVLl/qoY//WtWtXPf/888rPz9f+/fv1s5/9TPfcc4+OHDkiyQ/elwZwFYsWLTIGDBjg6zaaPUnGpk2bzMe1tbVGZGSk8cILL5jnysrKjJCQEOMvf/mLDzpsXr65noZhGElJScY999zjk36au9OnTxuSjNzcXMMwvn4vBgcHG5mZmWbNhx9+aEgy8vLyfNVms/DNtTQMw/iP//gPY+bMmb5rqpm74YYbjNdee80v3pdcacI1HTt2TFFRUbrxxhs1adIkFRUV+bqlZu/EiRNyu91KSEgwzzkcDsXHxysvL8+HnTVvu3btUnh4uHr37q1p06bpiy++8HVLzUJ5ebkkKSwsTJKUn5+v6upqr/dnnz591K1bN96f1/DNtazz+uuvq1OnTurbt68WLFigr776yhftNSs1NTVav369Kioq5HQ6/eJ9yY7guKr4+HhlZGSod+/eKikp0dNPP6077rhDhw8fVvv27X3dXrPldrslqd5u8xEREeYYGmbUqFEaN26cYmJidPz4cf3qV7/S6NGjlZeXp6CgIF+357dqa2s1a9Ys3Xbbberbt6+kr9+fNput3h8h5/15dVdaS0l64IEH1L17d0VFRengwYOaN2+eCgsL9cYbb/iwW/916NAhOZ1OXbx4Ue3atdOmTZsUGxurgoICn78vCU24qtGjR5v/7t+/v+Lj49W9e3dt3LhRycnJPuwM8DZx4kTz3/369VP//v110003adeuXRoxYoQPO/NvKSkpOnz4MPcqNoFvW8vHH3/c/He/fv3UpUsXjRgxQsePH9dNN930fbfp93r37q2CggKVl5frr3/9q5KSkpSbm+vrtiRxIzgaqEOHDrr55pv18ccf+7qVZi0yMlKS6n3ro7S01BzDd3PjjTeqU6dOvFevYvr06dqyZYt27typrl27mucjIyNVVVWlsrIyr3ren9/u29bySuLj4yWJ9+a3sNls6tmzp+Li4rRkyRINGDBAy5cv94v3JaEJDXL+/HkdP35cXbp08XUrzVpMTIwiIyOVk5NjnvN4PNq7d6+cTqcPO2s5Tp06pS+++IL36hUYhqHp06dr06ZN2rFjh2JiYrzG4+LiFBwc7PX+LCwsVFFREe/Pb7jWWl5JQUGBJPHetKi2tlaVlZV+8b7k13O4qjlz5ujuu+9W9+7dVVxcrEWLFikoKEj333+/r1vze+fPn/f6L8kTJ06ooKBAYWFh6tatm2bNmqVnn31WvXr1UkxMjH7zm98oKipKY8eO9V3Tfuxq6xkWFqann35a48ePV2RkpI4fP665c+eqZ8+ecrlcPuzaP6WkpGjdunX629/+pvbt25v3gzgcDoWGhsrhcCg5OVmpqakKCwuT3W7XjBkz5HQ6NWzYMB9371+utZbHjx/XunXrNGbMGHXs2FEHDx7U7Nmzdeedd6p///4+7t7/LFiwQKNHj1a3bt107tw5rVu3Trt27dK2bdv84335vXxHD83WhAkTjC5duhg2m8340Y9+ZEyYMMH4+OOPfd1Ws7Bz505DUr0jKSnJMIyvtx34zW9+Y0RERBghISHGiBEjjMLCQt827ceutp5fffWVMXLkSKNz585GcHCw0b17d+Oxxx4z3G63r9v2S1daR0nGmjVrzJoLFy4YTzzxhHHDDTcYbdq0Me69916jpKTEd037qWutZVFRkXHnnXcaYWFhRkhIiNGzZ0/jqaeeMsrLy33buJ965JFHjO7duxs2m83o3LmzMWLECOPtt982x339vgwwDMP4fuIZAABA88U9TQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACw4P8DMVFzcjL+3EEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_df.text.to_list()\n",
        "val_sentences = val_df.text.to_list()\n",
        "test_sentences = test_df.text.to_list()\n",
        "\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qvpqxpGIwEm",
        "outputId": "69a974ba-c166-4a72-d735-2e78e5783a33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6T3VrL1MQBP",
        "outputId": "abf377e6-8f60-4b35-86e6-9715bca57580"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output = False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df.target.to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df.target.to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df.target.to_numpy().reshape(-1, 1))"
      ],
      "metadata": {
        "id": "WraWQLVLMZMM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4vw6uvYnAoe",
        "outputId": "e126d298-7a51-47bc-f22b-eb688cb7de41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df.target.to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df.target.to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df.target.to_numpy())"
      ],
      "metadata": {
        "id": "SXY2mXvitAuW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_encoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Tz5ZX7oEve",
        "outputId": "538dbbd5-d81f-425d-b94e-85a665df09dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITH0_LGWxijx",
        "outputId": "ffd08496-f969-4e58-b627-851cfd65cf2b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([('Tf-idf', TfidfVectorizer()),\n",
        "                    ('clf', MultinomialNB())\n",
        "                    ])\n",
        "\n",
        "model_0.fit(\n",
        "    X = train_sentences,\n",
        "    y = train_labels_encoded\n",
        ")"
      ],
      "metadata": {
        "id": "iZcI5yOJxmJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "477437e1-cc57-4157-c173-e87347f5974d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('Tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(X = val_sentences,\n",
        "              y = val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6yrit0SRus",
        "outputId": "c2345ddf-2224-4b38-a2f8-7ec7634a1ef6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdQlfmNbTwtJ",
        "outputId": "22cfaab5-4e40-448a-818b-e094dbab56ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeJl_DTeVch-",
        "outputId": "1cd2d151-c354-466e-d579-085d703bc01e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-06 15:10:01--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-09-06 15:10:02 (17.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results\n",
        "\n",
        "baseline_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                     y_pred = baseline_preds)\n",
        "\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg2frByiXIm9",
        "outputId": "3f24277f-4866-4f56-ddf4-40ea78522237"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "zUWWtwhdXjdr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQm7q4k-d8hF",
        "outputId": "d1dad657-60d7-43dc-c821-80bf13c87fdc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(sent_lens, bins = 10);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "NeRpOft0g47h",
        "outputId": "c9a36350-2e06-492b-da3c-205584aadc29"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a7F_5YhiUhR",
        "outputId": "a058b3dd-7801-4b4d-ebd4-418dfe4b800f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 68000\n",
        "\n",
        "text_vectorizer = layers.TextVectorization(max_tokens = max_tokens,\n",
        "                                           output_sequence_length=output_seq_len,\n",
        "                                           pad_to_max_tokens = True)"
      ],
      "metadata": {
        "id": "H7EniEXkmPWb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "zlGjR3jjm7c8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.get_vocabulary()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8zw5dA5q1K9",
        "outputId": "002d9b91-80b4-40b7-f1ec-3a407b7fd43a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'and',\n",
              " 'of',\n",
              " 'in',\n",
              " 'to',\n",
              " 'with',\n",
              " 'a',\n",
              " 'were',\n",
              " 'was',\n",
              " 'for',\n",
              " 'patients',\n",
              " 'group',\n",
              " 'p',\n",
              " 'at',\n",
              " 'or',\n",
              " 'study',\n",
              " 'on',\n",
              " 'treatment']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "text_vectorizer([random_sentence]), random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pORrg_fTwjc2",
        "outputId": "2aa35b75-481b-4607-fb68-d3564a892acf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 55), dtype=int64, numpy=\n",
              " array([[ 1600,    85,    10,   153,   539,    49,   616, 25205,     3,\n",
              "            75,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0]])>,\n",
              " 'exploratory analysis was performed regarding baseline urinary pge-m and outcomes .')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "rct_20k_text_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ8AQlRgw5YF",
        "outputId": "b8c30a9e-674e-437e-dd77-72b80d8c4682"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embed = layers.Embedding(\n",
        "    input_dim = len(rct_20k_text_vocab),\n",
        "    output_dim = 128,\n",
        "    mask_zero = True,\n",
        "    name = 'token_embedding'\n",
        ")"
      ],
      "metadata": {
        "id": "tYTWhsFTqomk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_sentence)\n",
        "print(text_vectorizer([random_sentence]))\n",
        "print(token_embed(text_vectorizer([random_sentence])))\n",
        "print(token_embed(text_vectorizer([random_sentence])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz5dafhJutMe",
        "outputId": "f95fa2e2-7ae9-481b-bb49-382b71e96d6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exploratory analysis was performed regarding baseline urinary pge-m and outcomes .\n",
            "tf.Tensor(\n",
            "[[ 1600    85    10   153   539    49   616 25205     3    75     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]], shape=(1, 55), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[[ 0.03346721  0.0159066   0.03985185 ... -0.04372863 -0.02953488\n",
            "    0.02602949]\n",
            "  [-0.0448427  -0.0225112  -0.03935025 ... -0.00707419  0.01277813\n",
            "    0.00167793]\n",
            "  [ 0.01242912 -0.009636    0.00230499 ...  0.02518683  0.01188538\n",
            "   -0.0317613 ]\n",
            "  ...\n",
            "  [-0.00110613 -0.02572675 -0.04533701 ...  0.04235673 -0.02636685\n",
            "   -0.00400926]\n",
            "  [-0.00110613 -0.02572675 -0.04533701 ...  0.04235673 -0.02636685\n",
            "   -0.00400926]\n",
            "  [-0.00110613 -0.02572675 -0.04533701 ...  0.04235673 -0.02636685\n",
            "   -0.00400926]]], shape=(1, 55, 128), dtype=float32)\n",
            "(1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpwzZScJ1L3M",
        "outputId": "ae209c4e-2c45-47d0-cd6a-8f7023fc9234"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW9uOQ4uFXOM",
        "outputId": "aa43ced7-f2e5-4528-c9eb-6a293b0fde29"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = token_embed(x)\n",
        "x = tf.keras.layers.Conv1D(64, 5, padding = 'same', activation = 'relu')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.models.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "NYq6CGdEu9va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7457c3eb-3460-47da-c924-1e62f4764350"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "oMsco_OKL0uE",
        "outputId": "2d32ee20-50af-4cdf-d4b8-d68b981026ee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (\u001b[38;5;33mEmbedding\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │       \u001b[38;5;34m8,299,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m41,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,299,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,340,997\u001b[0m (31.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,340,997</span> (31.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,340,997\u001b[0m (31.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,340,997</span> (31.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy() ,\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "U40ICVlO2UIP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_1 = model_1.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = int(0.1 * len(train_dataset)),\n",
        "    epochs = 3,\n",
        "    validation_data = val_dataset,\n",
        "    validation_steps = int(0.1 * len(val_dataset))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHA5x9i26t3S",
        "outputId": "23a9e9aa-9bd3-4795-efc5-fe5ea967c13a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 1.1636 - val_accuracy: 0.7317 - val_loss: 0.7133\n",
            "Epoch 2/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7434 - loss: 0.6910 - val_accuracy: 0.7709 - val_loss: 0.6229\n",
            "Epoch 3/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7710 - loss: 0.6226 - val_accuracy: 0.7916 - val_loss: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9K8t2Fm7BUs",
        "outputId": "efeb7e8b-3e62-4d66-e67e-f3e6a34e2d7d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.5954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5972328782081604, 0.7852509021759033]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs = model_1.predict(val_dataset)\n",
        "model_1_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUchnfl95IZo",
        "outputId": "d389f157-65b0-42a8-cc55-10f75d4eea50"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3611798e-01, 1.7176098e-01, 6.0941521e-02, 2.9941443e-01,\n",
              "        3.1765133e-02],\n",
              "       [4.0021795e-01, 3.3073655e-01, 7.9975463e-03, 2.5020066e-01,\n",
              "        1.0847321e-02],\n",
              "       [1.6661997e-01, 6.5221107e-03, 1.7251362e-03, 8.2502824e-01,\n",
              "        1.0454168e-04],\n",
              "       ...,\n",
              "       [6.9679718e-06, 9.8685117e-04, 5.3731923e-04, 4.9228997e-06,\n",
              "        9.9846399e-01],\n",
              "       [3.7529290e-02, 4.7001639e-01, 6.3921556e-02, 4.4194791e-02,\n",
              "        3.8433805e-01],\n",
              "       [2.0594683e-01, 6.5699589e-01, 7.4704021e-02, 3.4746177e-02,\n",
              "        2.7607134e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds = tf.argmax(model_1_pred_probs, axis = 1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na51c1ACX-Ny",
        "outputId": "c90abe64-9529-4cf8-8b1d-2c2e608be963"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agJtMY5zz9jk",
        "outputId": "72cb971e-d191-4d3b-a568-34f67ecc2bde"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhCF3G5lZEa5",
        "outputId": "f9523d3d-549b-4872-8b50-135b4ad52fbd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.52508936846286,\n",
              " 'precision': 0.7815534064427281,\n",
              " 'recall': 0.7852508936846286,\n",
              " 'f1': 0.7827007481720855}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "    trainable=False, name='USE'\n",
        ")\n"
      ],
      "metadata": {
        "id": "AXU9RWLgZccL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the Universal Sentence Encoder (USE) as a Keras Layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "    input_shape=[],  # Input shape should be an empty list for string input\n",
        "    dtype=tf.string,  # Specify the dtype as tf.string\n",
        "    trainable=False,  # Set to False if you don't want to fine-tune the USE\n",
        "    name='USE'\n",
        ")\n",
        "\n",
        "# Define the inputs and model structure\n",
        "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string, name='input_text')\n",
        "use_output = sentence_encoder_layer(inputs)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(use_output)\n",
        "outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "I7NhQnvi_E4n",
        "outputId": "932306a9-77d8-4519-cb71-c7439b3225fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling layer 'USE' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=None, name=input_text>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'USE' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=None, name=input_text>\n  • training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-3e66e534099d>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Define the inputs and model structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0muse_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_encoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'USE' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=None, name=input_text>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'USE' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=None, name=input_text>\n  • training=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\")\n",
        "\n",
        "# Wrap the TensorFlow function 'embed' in a Keras layer\n",
        "class USE_Embedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed):\n",
        "        super(USE_Embedding, self).__init__()\n",
        "        self.embed = embed\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.embed(inputs)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string, name='input_text')\n",
        "# Use the custom layer to apply the embedding\n",
        "embeddings = USE_Embedding(embed)(inputs)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Disable XLA compilation\n",
        "tf.config.optimizer.set_jit(False)\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=int(0.1 * len(val_dataset)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fGhKabFR2fiI",
        "outputId": "635c789d-a626-4cf0-833e-5a8089637116"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_57735[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-53-56dd60be39e9>\", line 33, in <cell line: 33>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_57735[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_58136]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-56dd60be39e9>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_57735[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-53-56dd60be39e9>\", line 33, in <cell line: 33>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_57735[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_58136]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string, name='input_text')\n",
        "\n",
        "def use_layer(x):\n",
        "    embed = sentence_encoder_layer(x)\n",
        "    return embed\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "    trainable=False, name='USE'\n",
        ")\n",
        "\n",
        "use = tf.keras.layers.Lambda(use_layer,  output_shape=(512,))(inputs)\n",
        "x = layers.Dense(128, activation = 'relu')(use)\n",
        "outputs = layers.Dense(5, activation = 'softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "f83kqkO5bmf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model_2_history = model_2.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = int(0.1 * len(train_dataset)),\n",
        "    validation_data = val_dataset,\n",
        "    validation_steps = int(0.1 * len(val_dataset)),\n",
        "    epochs = 3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B0SdM7FPdQQr",
        "outputId": "1758317b-a7aa-47eb-deb1-df92027eee7a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_47504[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-58-ea17dd6c3268>\", line 7, in <cell line: 7>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_47504[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_47905]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ea17dd6c3268>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model_2_history = model_2.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_47504[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-58-ea17dd6c3268>\", line 7, in <cell line: 7>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_47504[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_47905]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "K2Mbk0RYeSDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "6-Ag9-5Npxak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs = model_2.predict(val_dataset)\n",
        "model_2_pred_probs"
      ],
      "metadata": {
        "id": "y6uY8gDRqlOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds = tf.argmax(model_2_pred_probs, axis = 1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "id": "OFDL8NQBqwnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "kEbQ2Rzuq3Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character level Embedding"
      ],
      "metadata": {
        "id": "7OxnIbHq5Hde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_chars(text):\n",
        "  return ' '.join(list(text))\n",
        "\n",
        "split_chars(random_sentence)"
      ],
      "metadata": {
        "id": "Nr8CHT5crsCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "\n",
        "train_chars[:5]"
      ],
      "metadata": {
        "id": "tU08wQdI9yRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[1]"
      ],
      "metadata": {
        "id": "pgWqspf27V0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "VBHZoK_5EBwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(char_lens, bins = 7);"
      ],
      "metadata": {
        "id": "PHJexFqZIpCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "PyC21Us1Jp41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "id": "iO4_1cdOJ45V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBKDDwPOAA03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import TextVectorization\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2\n",
        "char_vectorizer = TextVectorization(max_tokens = NUM_CHAR_TOKENS,\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    output_sequence_length = output_seq_char_len,\n",
        "                                    name = 'char_vectorizer')"
      ],
      "metadata": {
        "id": "gdC9VfKtmgQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "isC4JTtnn5yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "\n",
        "char_vocab, len(char_vocab)"
      ],
      "metadata": {
        "id": "CsSHlUqnoJ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_train_chars = random.choice(train_chars)\n",
        "char_vectorizer([random_train_chars])"
      ],
      "metadata": {
        "id": "yxR7i2OBofZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_embed = layers.Embedding(\n",
        "    input_dim = len(char_vocab),\n",
        "    output_dim = 25,\n",
        "    mask_zero = True,\n",
        "    name = 'char_embed'\n",
        ")"
      ],
      "metadata": {
        "id": "qx-AyZrIq33s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
        "\n",
        "x = char_vectorizer(inputs)\n",
        "x = char_embed(x)\n",
        "\n",
        "x = layers.Conv1D(64, kernel_size = 10, padding = 'same', activation = 'relu')(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n",
        "x = layers.Conv1D(16, kernel_size = 10, padding = 'same', activation = 'relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "outputs = layers.Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "model_3 = tf.keras.models.Model(inputs, outputs, name = 'model_3_conv1d_char_embedding')\n",
        "\n",
        "\n",
        "\n",
        "model_3.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "B2LEWm6m2lZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "wnk8-M1FPdL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "id": "_270o-vDSCHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                steps_per_epoch = int(0.1 * len(train_char_dataset)),\n",
        "                epochs = 3,\n",
        "                validation_data = val_char_dataset,\n",
        "                validation_steps = int(0.1 * len(val_char_dataset)))"
      ],
      "metadata": {
        "id": "3uYo8bLHTGOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "id": "Vxa45wwCUZRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds = tf.argmax(model_3_pred_probs, axis = 1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "id": "myD0MJl5VW8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_3_preds)\n",
        "\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "OG5k7OztVfMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Token level embedding\n",
        "token_inputs = layers.Input(shape = [], dtype = tf.string, name = 'token_input')\n",
        "token_embedding = sentence_encoder_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation = 'relu')(token_embedding)\n",
        "token_model = tf.keras.models.Model(token_inputs, token_outputs)\n",
        "\n",
        "#Character level embedding\n",
        "char_inputs = layers.Input(shape = (1, ), dtype = tf.string, name = 'char_input')\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embedding = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embedding)\n",
        "char_model = tf.keras.Model(char_inputs,\n",
        "                            char_bi_lstm)\n",
        "\n",
        "\n",
        "#Concatenate these two outputs\n",
        "token_char_concat = layers.Concatenate(name = 'token_char_hybrid')([token_model.output, char_model.output])\n",
        "\n",
        "\n",
        "#output layers\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(128, activation = 'relu')(combined_dropout)\n",
        "\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation = 'softmax')(final_dropout)\n",
        "\n",
        "\n",
        "#construct model\n",
        "model_4 = tf.keras.Model(inputs = [token_model.input, char_model.input],\n",
        "                         outputs = output_layer,\n",
        "                         name = 'model_4_token_and_char_embedding')"
      ],
      "metadata": {
        "id": "k8AGxr59VxCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_model.output"
      ],
      "metadata": {
        "id": "YV97AZ3xhtab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_model.input"
      ],
      "metadata": {
        "id": "q9Tn_bQXm2Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "id": "SyI71b74snK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model_4, show_shapes = True)"
      ],
      "metadata": {
        "id": "cAHjXnv7ttN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "PDzYsrJDSd4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
        "\n",
        "\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "di_GzHBYXHZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "test_char_token_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_chars))\n",
        "test_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_char_token_dataset = tf.data.Dataset.zip((test_char_token_data, test_char_token_labels))\n",
        "\n",
        "test_char_token_dataset = test_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "crWRz97B2uTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_token_dataset"
      ],
      "metadata": {
        "id": "N5jRihEA3zXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_4 = model_4.fit(train_char_token_dataset,\n",
        "                              steps_per_epoch = int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs = 3,\n",
        "                              validation_data = val_char_token_dataset,\n",
        "                              validation_steps = int(0.1 * len(val_char_token_dataset)))"
      ],
      "metadata": {
        "id": "Y7W40kIM6Uuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "t54u0EZw9d94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis = 1)\n",
        "model_4_preds"
      ],
      "metadata": {
        "id": "MJ9K3E-UAi97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_4_preds)\n",
        "\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "7AQEyvqCAzBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results"
      ],
      "metadata": {
        "id": "lRCJpw-_UxKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "VcJ8g0UxDe2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "NLtv-PSX421M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['line_number'].value_counts()"
      ],
      "metadata": {
        "id": "RygNOjh16_Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(train_df.line_number, 98)"
      ],
      "metadata": {
        "id": "MVUQ9RL-JAje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_numbers_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth = 15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df['line_number'].to_numpy(), depth = 15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df['line_number'].to_numpy(), depth = 15)\n",
        "train_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "75Hxa6dL_LJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.value_counts()"
      ],
      "metadata": {
        "id": "ZVJTQFWwCn1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "id": "Rh6FbJUaEbnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(train_df.total_lines, 98)"
      ],
      "metadata": {
        "id": "35ROK2-GHDFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_total_lines_one_hot = tf.one_hot(train_df.total_lines.to_numpy(), depth = 20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df.total_lines.to_numpy(), depth = 20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df.total_lines.to_numpy(), depth = 20)"
      ],
      "metadata": {
        "id": "J8xZMD6BI8My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_inputs = layers.Input(shape = [], dtype = tf.string, name = 'token_inputs')\n",
        "token_embedding = sentence_encoder_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation = 'relu')(token_embedding)\n",
        "\n",
        "token_model = tf.keras.Model(token_inputs, token_outputs)\n",
        "\n",
        "\n",
        "\n",
        "char_inputs = layers.Input(shape = (1, ), dtype = tf.string, name = 'char_inputs')\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
        "\n",
        "char_model = tf.keras.Model(char_inputs, char_bi_lstm)"
      ],
      "metadata": {
        "id": "M2EaLrL-J8Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot.dtype"
      ],
      "metadata": {
        "id": "ut_vMq9EBRqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_number_inputs = layers.Input(shape = (15, ), dtype = tf.float32, name = 'line_numbers_input')\n",
        "line_number_outputs = layers.Dense(32, activation = 'relu')(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(line_number_inputs, line_number_outputs)\n",
        "\n",
        "\n",
        "\n",
        "total_lines_inputs = layers.Input(shape = (20, ), dtype = tf.float32, name = 'total_lines_input')\n",
        "total_lines_outputs = layers.Dense(32, activation = 'relu')(total_lines_inputs)\n",
        "total_lines_model = tf.keras.Model(total_lines_inputs, total_lines_outputs)"
      ],
      "metadata": {
        "id": "M1h1hX8k_Dyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = layers.Concatenate(name = 'char_token_hybrid_embedding')([token_model.output, char_model.output])\n",
        "\n",
        "z = layers.Dense(256, activation = 'relu')(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)"
      ],
      "metadata": {
        "id": "fuu2j1YbBv7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tribrid_embeddings = layers.Concatenate(name = 'char_token_positional_embeddings')([line_number_model.output,\n",
        "                                                                                    total_lines_model.output,\n",
        "                                                                                    z])\n",
        "\n",
        "\n",
        "output_layer = layers.Dense(5, activation = 'softmax', name= 'output_layers')(tribrid_embeddings)"
      ],
      "metadata": {
        "id": "p4Lwc2rIMtqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = tf.keras.Model(inputs = [line_number_model.input,\n",
        "                          total_lines_model.input,\n",
        "                          token_model.input,\n",
        "                          char_model.input],\n",
        "                         outputs = output_layer,\n",
        "                         name = 'model_5_tribrid_embedding_layer')"
      ],
      "metadata": {
        "id": "iXCgALsVN9De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "id": "zUfqsdH4Pyin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model_5, show_shapes = True)"
      ],
      "metadata": {
        "id": "cmo9UdHVRR5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "3AIDfWFXR0zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and valiadation datasets (with all four kinds of input data)\n",
        "train_char_token_pos_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,\n",
        "                                                                train_total_lines_one_hot,\n",
        "                                                                train_sentences,\n",
        "                                                                train_chars))\n",
        "train_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_char_token_pos_dataset = tf.data.Dataset.zip((train_char_token_pos_data, train_char_token_pos_labels))\n",
        "train_char_token_pos_dataset = train_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Do the same as above but for the validation dataset\n",
        "val_char_token_pos_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_pos_dataset = tf.data.Dataset.zip((val_char_token_pos_data, val_char_token_pos_labels))\n",
        "val_char_token_pos_dataset = val_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "Mugs5zp1jJjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_char_token_pos_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_pos_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_pos_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_pos_dataset)))"
      ],
      "metadata": {
        "id": "cwUIWQWgo21V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(val_char_token_pos_dataset)"
      ],
      "metadata": {
        "id": "JsT_i_p6FAnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs = model_5.predict(val_char_token_pos_dataset)\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis = 1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "id": "GDs9P9CsLrsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "iNQa9_U3L5e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"model_0_baseline\": baseline_results,\n",
        "                                  \"model_1_custom_token_embedding\": model_1_results,\n",
        "                                  \"model_2_pretrained_token_embedding\": model_2_results,\n",
        "                                  \"model_3_custom_char_embedding\": model_3_results,\n",
        "                                  \"model_4_hybrid_char_token_embedding\": model_4_results,\n",
        "                                  \"model_5_pos_char_token_embedding\": model_5_results})\n",
        "\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "Ki-F55NtRWK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(token_inputs)\n",
        "x = token_embed(x)\n",
        "x = tf.keras.layers.Conv1D(64, 5, padding = 'same', activation = 'relu')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "token_outputs = tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "token_model = tf.keras.Model(token_inputs, token_outputs)\n",
        "\n",
        "\n",
        "\n",
        "char_inputs = layers.Input(shape = (1, ), dtype = tf.string, name = 'char_inputs')\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
        "\n",
        "char_model = tf.keras.Model(char_inputs, char_bi_lstm)\n",
        "\n",
        "\n",
        "line_number_inputs = layers.Input(shape = (15, ), dtype = tf.float32, name = 'line_numbers_input')\n",
        "line_number_outputs = layers.Dense(32, activation = 'relu')(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(line_number_inputs, line_number_outputs)\n",
        "\n",
        "\n",
        "\n",
        "total_lines_inputs = layers.Input(shape = (15, ), dtype = tf.float32, name = 'total_lines_input')\n",
        "total_lines_outputs = layers.Dense(32, activation = 'relu')(total_lines_inputs)\n",
        "total_lines_model = tf.keras.Model(total_lines_inputs, total_lines_outputs)\n",
        "\n",
        "\n",
        "combined_embeddings = layers.Concatenate(name = 'char_token_hybrid_embedding')([token_model.output, char_model.output])\n",
        "\n",
        "z = layers.Dense(256, activation = 'relu')(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "\n",
        "\n",
        "tribrid_embeddings = layers.Concatenate(name = 'char_token_positional_embeddings')([line_number_model.output,\n",
        "                                                                                    total_lines_model.output,\n",
        "                                                                                    z])\n",
        "\n",
        "\n",
        "output_layer = layers.Dense(5, activation = 'softmax', name= 'output_layers')(tribrid_embeddings)"
      ],
      "metadata": {
        "id": "VlCHFyBaZfOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = tf.keras.Model(inputs = [line_number_model.input,\n",
        "                          total_lines_model.input,\n",
        "                          token_model.input,\n",
        "                          char_model.input],\n",
        "                         outputs = output_layer,\n",
        "                         name = 'model_5_tribrid_embedding_layer')"
      ],
      "metadata": {
        "id": "yAWuV9nYbIY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "DvBojyJhbMRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_6 = model_6.fit(train_char_token_pos_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_pos_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_pos_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_pos_dataset)))"
      ],
      "metadata": {
        "id": "K3CM1imSbfCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "foJO_tGYbj5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results.plot(kind = 'bar', figsize = (10, 7)).legend(bbox_to_anchor = (1.0, 1.0))"
      ],
      "metadata": {
        "id": "9EdZYhJqb3m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results.sort_values('f1', ascending = True)['f1'].plot(kind = 'bar', figsize = (10, 7))"
      ],
      "metadata": {
        "id": "ed7JjauJcU_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.save(\"skimlit_tribrid_model\")"
      ],
      "metadata": {
        "id": "ZE-3Mo46d7xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/skimlit_tribrid_model')"
      ],
      "metadata": {
        "id": "6mfoP7g4FKab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.evaluate(val_char_token_pos_dataset)"
      ],
      "metadata": {
        "id": "tamsYMAcF0uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "GM3mH-3vGEPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
        "!mkdir skimlit_gs_model\n",
        "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
      ],
      "metadata": {
        "id": "1CSlpQ_iHuEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model = tf.keras.models.load_model(\"/content/skimlit_gs_model/skimlit_tribrid_model\")"
      ],
      "metadata": {
        "id": "ebDcmSXbKifH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the most wrong predictions"
      ],
      "metadata": {
        "id": "ggmJieeWK5nl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}